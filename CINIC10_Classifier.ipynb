{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1GiV7X--Emq7",
    "outputId": "93d6d3f0-667c-4de4-e7d9-18bd880a2648"
   },
   "outputs": [],
   "source": [
    "#this code has been run in Google Colab using GPU, all pieces of code are programmed accordingly\n",
    "#this piece of code is to determine if a GPU is connected and report the properties\n",
    "import tensorflow as tf\n",
    "import os\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    " process = psutil.Process(os.getpid())\n",
    " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "id": "P9KnhApZEmrF",
    "outputId": "a979099c-a29b-4517-b60d-912c9453c3c3"
   },
   "outputs": [],
   "source": [
    "#downloads necessary libraries, creates a subdirectory named \"data\" and downloads the given dataset to that directory\n",
    "! pip install -q kaggle\n",
    "from google.colab import files\n",
    "files.upload()\n",
    "\n",
    "! mkdir ~/.kaggle\n",
    "\n",
    "! cp kaggle.json ~/.kaggle/\n",
    "\n",
    "! chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "! kaggle datasets list\n",
    "\n",
    "! kaggle datasets download -d mengcius/cinic10\n",
    "\n",
    "! mkdir data\n",
    "! unzip cinic10.zip -d data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DeckNmQfEmrG"
   },
   "outputs": [],
   "source": [
    "import numpy as np #to do matrix and array operations quickly\n",
    "\n",
    "from tensorflow.keras.models import Sequential #to create a model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout\n",
    "\n",
    "from sklearn import metrics # to give reports about recall, precision, recall and confusion matrix\n",
    "\n",
    "\n",
    "def try_cnn_comb(train_generator, test_generator, valid_generator): #takes 3 generators that will be used in training, test and validation; sends parameters of 6 different combination of CNNs to a function that will train that model\n",
    "    layers = [2,3]\n",
    "    kernels = [3,5]\n",
    "    dropout = [0.2,0.7]\n",
    "    for x in layers: # for each layer\n",
    "        for y in kernels: # for each kernel size\n",
    "          if y == 3: # if kernel size is 3, then try for all dropout rates\n",
    "            for z in dropout:\n",
    "              run_cnn_comb(x, y, z, train_generator, test_generator, valid_generator)\n",
    "          else: # if kernel size is 5, then try for only 0.2 dropout rate\n",
    "            run_cnn_comb(x, y, 0.2, train_generator, test_generator, valid_generator)           \n",
    "            \n",
    "def run_cnn_comb(layer_count, kernel_size, dropout_rate, train_generator, test_generator, valid_generator): #creates a model with given parameters, and passes the model and the data to another function that will fit the model and print a detailed report of the outcome\n",
    "    model = Sequential() #creates a sequential model\n",
    "    model.add(Conv2D(32, kernel_initializer='GlorotNormal', kernel_size=kernel_size, activation='relu', input_shape=(224,224,3))) #adds a 2D convolution layer\n",
    "    model.add(Dropout(dropout_rate)) #adds a dropout layer with the given dropout rate\n",
    "    for i in range(layer_count-1): #adds these layers again and again untill it reaches the requested amount of layers\n",
    "        model.add(Conv2D(32, kernel_initializer='GlorotNormal', kernel_size=kernel_size, activation='relu'))\n",
    "        model.add(Dropout(dropout_rate))\n",
    "    model.add(Flatten()) #flattens the data to pass it to the final dense layer\n",
    "    model.add(Dense(10, kernel_initializer='GlorotNormal', activation = 'softmax')) # adds the final layer that will give an outcome\n",
    "    \n",
    "    model.summary() # prints model's specifications\n",
    "\n",
    "    fit_report_models(train_generator, test_generator, valid_generator, model) # sends the data and the model to a function that will fit the model and report the outcome with confusion matrix\n",
    "\n",
    "def fit_report_models(train_generator, test_generator, valid_generator, model): # takes generator datas and a model to fit the model and report an outcome with statistical success rates and a confusion matrix\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) #compiles the given model with adam optimizer\n",
    "    \n",
    "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size # calculates the amount of steps in an epoch to completely traverse the data\n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "    \n",
    "    model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN+1, validation_data=valid_generator, validation_steps=STEP_SIZE_VALID+1, epochs=5) # trains the model\n",
    "\n",
    "    predictions = model.predict_generator(test_generator, steps=STEP_SIZE_TEST+1) # finds predictions with the test data\n",
    "\n",
    "    predicted_classes = np.argmax(predictions, axis=1) # gets most likely class\n",
    "\n",
    "    true_classes = test_generator.classes # list of true class labels\n",
    "    class_labels = list(test_generator.class_indices.keys()) # gets all the labels\n",
    "\n",
    "    report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels) # print a table of recall, precision and f1 score for each label\n",
    "    print(report)\n",
    "    confusion_matrix = metrics.confusion_matrix(y_true=true_classes, y_pred=predicted_classes) # creates a confusion matrix\n",
    "    print(confusion_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kfMC8D9PEmrH",
    "outputId": "4a6f8d82-3bbf-409b-c8e4-11fdf638a589"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator # since getting all the data at once will create memory issues, generator will be used\n",
    "\n",
    "train_gen = ImageDataGenerator(rescale=1./255) # creates a generator object that will normalize pixel values between 0 and 1\n",
    "train_generator = train_gen.flow_from_directory(\n",
    "    directory=\"data/train/\", #data will be taken from this path\n",
    "    target_size=(224, 224), #data will be resized to 224x224\n",
    "    color_mode=\"rgb\", #pixel values will be rgb\n",
    "    batch_size=64, # 64 datas will be taken in each step in each epoch\n",
    "    class_mode=\"categorical\", # data is categorical\n",
    "    shuffle=True, # shuffle to data to better train the model\n",
    "    seed=42 # use a fixed seed to get the same randomization each time to compare the success rates\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=\"data/test/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=False,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    directory=\"data/valid/\",\n",
    "    target_size=(224, 224),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=64,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh3WF5UiEmrI",
    "outputId": "ccb170f0-fb9d-41be-bd91-fd33102768f9"
   },
   "outputs": [],
   "source": [
    "try_cnn_comb(train_generator, test_generator, val_generator) # with this generators, creates all 6 combinations of models in the project document and makes a report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YMdzALCyEmrJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16 # imports VGG model to use the pretrained model\n",
    "from tensorflow.keras.preprocessing import image \n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Model # to use a pretrained model as a \"model\" to add it to another model\n",
    "\n",
    "modelvgg = VGG16(weights='imagenet') # loads vgg model\n",
    "\n",
    "modelvgg.layers.pop() # pops last layer\n",
    "\n",
    "for i in range(len(modelvgg.layers)): # makes each layer untrainable\n",
    "  modelvgg.layers[i].trainable = False\n",
    "\n",
    "model = Sequential() # creates a new model since we can't manipulate a pretrained model\n",
    "model.add(Model(modelvgg.input, modelvgg.layers[-2].output)) # adds the pretrained model to this model without the last layer\n",
    "model.add(Dense(1024, trainable = True, activation='relu')) # adds a 1024-node trainable dense layer \n",
    "model.add(Dense(10, trainable = True, activation = 'softmax')) # adds an output layer\n",
    "\n",
    "model.summary() # prints a summary of the model\n",
    "\n",
    "fit_report_models(train_generator, test_generator, val_generator, model) # fits the model and reports the outcome\n",
    "\n",
    "for i in range(4):\n",
    "  modelvgg.layers[(-1)*i].trainable = True # makes the last 4 layers of the pretrained vgg model trainable\n",
    "\n",
    "model = Sequential() # creates a new model and follows the same steps with the previous model\n",
    "model.add(Model(modelvgg.input, modelvgg.layers[-2].output))\n",
    "model.add(Dense(1024, trainable = True, activation='relu'))\n",
    "model.add(Dense(10, trainable = True, activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "fit_report_models(train_generator, test_generator, val_generator, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oq3AJ8uoEmrJ"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50 # imports resnet model to use the pretrained model\n",
    "\n",
    "modelvgg = ResNet50(weights= None, input_shape= (224,224,3)) # follows the same steps with vgg model for the resnet model\n",
    "\n",
    "modelvgg.layers.pop()\n",
    "\n",
    "for i in range(len(modelvgg.layers)):\n",
    "  modelvgg.layers[i].trainable = False\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Model(modelvgg.input, modelvgg.layers[-2].output))\n",
    "model.add(Dense(1024, trainable = True, activation='relu'))\n",
    "model.add(Dense(10, trainable = True, activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "fit_report_models(train_generator, test_generator, val_generator, model)\n",
    "\n",
    "for i in range(4):\n",
    "  modelvgg.layers[(-1)*i].trainable = True\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Model(modelvgg.input, modelvgg.layers[-2].output))\n",
    "model.add(Dense(1024, trainable = True, activation='relu'))\n",
    "model.add(Dense(10, trainable = True, activation = 'softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "fit_report_models(train_generator, test_generator, val_generator, model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "imageProcessingProject.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
